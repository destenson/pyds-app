# Static Analysis CI Pipeline
# Runs comprehensive static analysis on pull requests and main branch pushes
# Supports Windows, Linux, and macOS environments

name: Static Analysis

on:
  push:
    branches: [ main, master, develop ]
  pull_request:
    branches: [ main, master, develop ]
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  PYTHON_VERSION: '3.11'
  UV_CACHE_DIR: ~/.cache/uv
  
jobs:
  static-analysis:
    name: Static Analysis
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest]
        include:
          - os: ubuntu-latest
            cache-path: ~/.cache/uv
          - os: windows-latest
            cache-path: ~\AppData\Local\uv\cache
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for trend analysis
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install uv (Unix)
      if: runner.os != 'Windows'
      run: curl -LsSf https://astral.sh/uv/install.sh | sh
    
    - name: Install uv (Windows)
      if: runner.os == 'Windows'
      run: |
        irm https://astral.sh/uv/install.ps1 | iex
        echo "$HOME\.cargo\bin" | Out-File -FilePath $env:GITHUB_PATH -Encoding utf8 -Append
    
    - name: Cache uv dependencies
      uses: actions/cache@v3
      with:
        path: ${{ matrix.cache-path }}
        key: ${{ runner.os }}-uv-${{ hashFiles('pyproject.toml', 'uv.lock') }}
        restore-keys: |
          ${{ runner.os }}-uv-
    
    - name: Install dependencies
      run: uv sync --extra dev
    
    - name: Cache analysis tools
      uses: actions/cache@v3
      with:
        path: |
          ~/.cache/semgrep
          ~/.cache/bandit
        key: ${{ runner.os }}-analysis-tools-${{ hashFiles('.pre-commit-config.yaml') }}
    
    - name: Run Ruff linting
      run: uv run ruff check src/ --format github
      continue-on-error: true
    
    - name: Run Ruff formatting check
      run: uv run ruff format src/ --check
      continue-on-error: true
    
    - name: Run MyPy type checking
      run: uv run mypy src/ --config-file pyproject.toml
      continue-on-error: true
    
    - name: Run Bandit security scan
      run: |
        uv run bandit -r src/ -f json -o analysis/reports/bandit-results.json
        uv run bandit -r src/ -f txt
      continue-on-error: true
    
    - name: Run Vulture dead code detection
      run: uv run vulture src/ --min-confidence 80
      continue-on-error: true
    
    - name: Setup Semgrep
      if: runner.os != 'Windows'  # Semgrep has limited Windows support
      run: |
        pip install semgrep
        semgrep --version
    
    - name: Run Semgrep security scan
      if: runner.os != 'Windows'
      run: |
        semgrep --config=analysis/rules/ src/ --json --output=analysis/reports/semgrep-results.json
        semgrep --config=analysis/rules/ src/
      continue-on-error: true
    
    - name: Run unified static analysis
      run: |
        mkdir -p analysis/reports
        uv run python scripts/static-analysis.py --all-tools --output analysis/reports/unified-analysis.json
      continue-on-error: true
    
    - name: Run security-focused scan
      run: |
        uv run python scripts/security-scan.py --all --output analysis/reports/security-scan.json
      continue-on-error: true
    
    - name: Upload analysis reports
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: static-analysis-reports-${{ matrix.os }}
        path: |
          analysis/reports/
          htmlcov/
        retention-days: 30
    
    - name: Comment PR with analysis summary
      if: github.event_name == 'pull_request' && runner.os == 'ubuntu-latest'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const path = 'analysis/reports/unified-analysis.json';
          
          if (fs.existsSync(path)) {
            const report = JSON.parse(fs.readFileSync(path, 'utf8'));
            const summary = report.summary || {};
            
            const comment = `## üîç Static Analysis Summary
            
            **Total Issues:** ${summary.total_issues || 0}
            **Tools Run:** ${report.tools_run ? report.tools_run.join(', ') : 'Unknown'}
            **Duration:** ${report.total_duration ? report.total_duration.toFixed(2) : 'Unknown'}s
            
            ### Issues by Severity
            ${Object.entries(summary.issues_by_severity || {}).map(([severity, count]) => 
              `- **${severity}:** ${count}`
            ).join('\n')}
            
            ### Issues by Category  
            ${Object.entries(summary.issues_by_category || {}).map(([category, count]) => 
              `- **${category}:** ${count}`
            ).join('\n')}
            
            üìä View detailed reports in the [workflow artifacts](${context.payload.pull_request.html_url}/checks).
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
          }

  test-coverage:
    name: Test Coverage Analysis
    runs-on: ubuntu-latest
    needs: static-analysis
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install uv
      run: curl -LsSf https://astral.sh/uv/install.sh | sh
    
    - name: Install dependencies
      run: uv sync --extra dev
    
    - name: Run tests with coverage
      run: |
        uv run python scripts/coverage-analysis.py --run-tests --correlate-dead-code --output analysis/reports/coverage-analysis.json
    
    - name: Generate coverage badge
      run: |
        uv run coverage-badge -o coverage-badge.svg
    
    - name: Upload coverage reports
      uses: actions/upload-artifact@v3
      with:
        name: coverage-reports
        path: |
          analysis/reports/coverage-analysis.json
          analysis/coverage/reports/
          coverage-badge.svg
        retention-days: 30
    
    - name: Upload coverage to Codecov
      if: runner.os == 'Linux'
      uses: codecov/codecov-action@v3
      with:
        file: analysis/coverage/reports/coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

  quality-gate:
    name: Quality Gate
    runs-on: ubuntu-latest
    needs: [static-analysis, test-coverage]
    if: always()
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Download analysis reports
      uses: actions/download-artifact@v3
      with:
        name: static-analysis-reports-ubuntu-latest
        path: analysis/reports/
    
    - name: Download coverage reports
      uses: actions/download-artifact@v3
      with:
        name: coverage-reports
        path: analysis/reports/
    
    - name: Evaluate quality gate
      run: |
        python3 << 'EOF'
        import json
        import sys
        from pathlib import Path
        
        # Quality gate thresholds
        MAX_CRITICAL_ISSUES = 0
        MAX_HIGH_ISSUES = 5
        MIN_COVERAGE = 85.0
        
        exit_code = 0
        
        # Check static analysis results
        analysis_file = Path('analysis/reports/unified-analysis.json')
        if analysis_file.exists():
            with open(analysis_file) as f:
                analysis = json.load(f)
            
            summary = analysis.get('summary', {})
            issues_by_severity = summary.get('issues_by_severity', {})
            
            critical_issues = issues_by_severity.get('critical', 0)
            high_issues = issues_by_severity.get('high', 0)
            
            print(f"Critical issues: {critical_issues} (max: {MAX_CRITICAL_ISSUES})")
            print(f"High severity issues: {high_issues} (max: {MAX_HIGH_ISSUES})")
            
            if critical_issues > MAX_CRITICAL_ISSUES:
                print(f"‚ùå FAIL: {critical_issues} critical issues found (max: {MAX_CRITICAL_ISSUES})")
                exit_code = 1
            
            if high_issues > MAX_HIGH_ISSUES:
                print(f"‚ùå FAIL: {high_issues} high severity issues found (max: {MAX_HIGH_ISSUES})")
                exit_code = 1
        
        # Check coverage results
        coverage_file = Path('analysis/reports/coverage-analysis.json')
        if coverage_file.exists():
            with open(coverage_file) as f:
                coverage = json.load(f)
            
            overall_coverage = coverage.get('coverage_report', {}).get('overall_coverage', 0)
            
            print(f"Test coverage: {overall_coverage:.1f}% (min: {MIN_COVERAGE}%)")
            
            if overall_coverage < MIN_COVERAGE:
                print(f"‚ùå FAIL: Coverage {overall_coverage:.1f}% below minimum {MIN_COVERAGE}%")
                exit_code = 1
        
        if exit_code == 0:
            print("‚úÖ Quality gate passed!")
        else:
            print("‚ùå Quality gate failed!")
        
        sys.exit(exit_code)
        EOF
    
    - name: Fail if quality gate not met
      if: failure()
      run: |
        echo "Quality gate failed. Check the analysis results above."
        exit 1